from pymilvus import (
    connections, FieldSchema, CollectionSchema, DataType,
    Collection, utility
)
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import json
import numpy as np
import time

# --- 1Ô∏è‚É£ Conexi√≥n a Milvus ---
connections.connect("default", host="milvus", port="19530")

# --- 2Ô∏è‚É£ Par√°metros generales ---
collection_name = "violaciones_cev_vectors"
embedding_dim = 384  # Dimensi√≥n del modelo multilingual-MiniLM

# --- 3Ô∏è‚É£ Elimina colecci√≥n previa si existe ---
if utility.has_collection(collection_name):
    utility.drop_collection(collection_name)

# --- 4Ô∏è‚É£ Define esquema ---
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
    FieldSchema(name="text_raw", dtype=DataType.VARCHAR, max_length=2048),
    FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),
]
schema = CollectionSchema(fields, description="Corpus embeddings multiling√ºes")

# --- 5Ô∏è‚É£ Crear colecci√≥n ---
collection = Collection(name=collection_name, schema=schema)
print(f"‚úÖ Colecci√≥n creada: {collection_name}")

# --- 6Ô∏è‚É£ Modelo de embeddings multiling√ºe ---
model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
model = SentenceTransformer(model_name)

# --- 7Ô∏è‚É£ Cargar corpus JSONL ---
data_path = "/data/corpus/books_preprocessed.jsonl"
texts, ids = [], []

with open(data_path, "r", encoding="utf-8") as f:
    for i, line in enumerate(f):
        obj = json.loads(line)
        text = obj.get("text_raw", "")
        if text:
            ids.append(i)
            texts.append(text)

print(f"üìö Documentos le√≠dos: {len(texts)}")

# --- 8Ô∏è‚É£ Generar embeddings ---
print("üß† Generando embeddings multiling√ºes...")
embeddings = model.encode(texts, show_progress_bar=True, convert_to_numpy=True)

# --- 9Ô∏è‚É£ Insertar en Milvus ---
print("üì§ Insertando en Milvus...")
collection.insert([ids, texts, embeddings])
collection.flush()
print(f"‚úÖ Insertados {len(texts)} documentos en Milvus.")

# --- üîü Crear √≠ndice (para b√∫squedas r√°pidas) ---
index_params = {
    "metric_type": "IP",  # Inner Product (cosine similarity)
    "index_type": "HNSW",  # Alta velocidad para b√∫squedas sem√°nticas
    "params": {"M": 32, "efConstruction": 200}
}
collection.create_index(field_name="embedding", index_params=index_params)
print("‚úÖ √çndice creado correctamente.")

# --- 1Ô∏è‚É£1Ô∏è‚É£ Verificar b√∫squeda ---
collection.load()

query_text = "violaci√≥n final"
query_vec = model.encode([query_text])

results = collection.search(
    data=query_vec,
    anns_field="embedding",
    param={"metric_type": "IP", "params": {"ef": 128}},
    limit=5,
    output_fields=["text_raw"]
)

print("\nüîç Resultados de b√∫squeda para:", query_text)
for hit in results[0]:
    print(f" - (score={hit.score:.3f}) {hit.entity.get('text_raw')[:120]}")

print("\n‚úÖ Validaci√≥n de √≠ndice y b√∫squeda completada.")
